{"cells":[{"cell_type":"markdown","metadata":{"id":"XUhDtCFJvPDZ"},"source":["# How to use Gymnasium\n","Gymnasium is a toolkit comprised with several environments aimed at testing and comparing diferent reinforcement learning algorithms. Gymnasium supersedes OpenAI's Gym toolkit\n","\n","They provide 7 groups of environments:\n","\n","* Algorithms: Text-based environments to train how to do computations.\n","* Atari: Environments based on atari games like pong.\n","* Box2D: 2D control task environments.\n","* Classic control: Classic problems present in RL literature.\n","* MuJoCo: 3D continuous control task environments.\n","* Robotics: 3D environments featuring a robot arm or robot hand.\n","* Toy text: Simple environments in which the state is rendered  as text.\n","\n","For more information check the [Gymnasium](https://gymnasium.farama.org/)."]},{"cell_type":"markdown","metadata":{"id":"QHB9ZgR9wGhR"},"source":["## Installing Gymnasium on Google Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1747,"status":"ok","timestamp":1706029864695,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"6y8fKxgXwKcD","outputId":"5440593a-9a66-4b56-d740-d0578b7919b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym[all] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n"]}],"source":["# Uncomment the next lines\n","!pip install gym[all]  --no-deps"]},{"cell_type":"markdown","metadata":{"id":"I-4R-iOpS8S8"},"source":["## Gym Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":475,"status":"ok","timestamp":1706029865562,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"S2PT-VaAvcxm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48ab73db-537d-43c3-8191-40a101e6d633"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.25.2\n"]}],"source":["import gym as gym\n","print(gym.__version__)"]},{"cell_type":"markdown","metadata":{"id":"fLmsf6fBUeSI"},"source":["## Instantiate the Environment\n","At this point you call the method `make` of the gym class to instantiate the desired environment and arguments if required."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1706031449091,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"sOeztZBbUk3P","colab":{"base_uri":"https://localhost:8080/"},"outputId":"13746927-ae02-4be2-8aa6-b9ca4ba2e3d2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["env = gym.make('Blackjack-v1')"]},{"cell_type":"markdown","metadata":{"id":"C8bWbY4XapPA"},"source":["In this case the environment is a blackjack card game.\n","\n","In this game the player's goal is to obtain cards that sum to as close as possible to 21 without going over.\n","\n","The game starts with the dealer having one face up and one face down card and the player having two face up cards. The player has two possibilities:\n","- Hit (get another card)\n","- Stick (stay with the cards he already has)\n","If the sum of the player's cards is over 21, the player busts.\n","\n","After the player sticks, the dealer reveals his facedown card, and draws until the sum is 17 or greater. If the dealer goes bust the player wins.\n","\n","If neither player nor dealer busts, the outcome (win, lose, draw) is decided by whose sum is closer to 21.\n","\n","The reward for winning is +1, drawing is 0, and losing is -1. If the player wins with a natural blackjack (an A and a 10), the winning is worth +1.5."]},{"cell_type":"markdown","metadata":{"id":"202m8zypTWQr"},"source":["## Checking the State and Action Spaces"]},{"cell_type":"markdown","metadata":{"id":"5AD28C5Uwy15"},"source":["To check the shape of the state space, simply call `observation_space` on the environment variable:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1706031451986,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"VjdAnjw8w1Ea","outputId":"26d7d851-400d-4628-c243-94d2d42ed279"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tuple(Discrete(32), Discrete(11), Discrete(2))"]},"metadata":{},"execution_count":104}],"source":["env.observation_space"]},{"cell_type":"markdown","metadata":{"id":"pRi7U3ywyMCu"},"source":["For this environment the observation space is:\n","\n","1. The sum of the 2 cards in the player's hand. The sum is at most 31.\n","2. The card that the dealer is currently showing. The cards' values are\n"," - Ace may have a value of 10 (usable ace) or 1 (non usable ace).\n"," - Number cards keep their values, from 2 to 10.\n"," - Face cards J, Q, and K have a value of 10.\n","3. If the player has an usable ace or not.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YGUeyfN3xmGG"},"source":["To get a random observation call the `sample()` method on the `observation_space`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706031452337,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"8gVKhnPUx5Ie","outputId":"d07a39d9-0e43-4f3d-e295-97c8c48a2955"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 7, 1)"]},"metadata":{},"execution_count":105}],"source":["env.observation_space.sample()"]},{"cell_type":"markdown","metadata":{"id":"SY_i62Tkx9kn"},"source":["The same goes for the action space:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706031453795,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"m8FsaCFeyEWG","outputId":"b4685640-8d61-4c38-af3b-b2534a42775c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(2)"]},"metadata":{},"execution_count":106}],"source":["env.action_space"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1706031454816,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"8g5I9ARzyGde","outputId":"e8afacfe-c292-4078-b32e-793052a24763"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":107}],"source":["env.action_space.sample()"]},{"cell_type":"markdown","metadata":{"id":"_EhYmwrhVb2h"},"source":["## Resetting the Environment\n","\n","Resetting the environment means to begin a **new episode** and get the **starting observation**. With Gym, use the method `reset()` on the environment instance."]},{"cell_type":"code","source":["observation, info = env.reset()"],"metadata":{"id":"BnRiqhQWT_xN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706029922556,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"XaJiXcatWgYx","outputId":"3a8d717c-12e0-405b-810a-f49b1584dcf5"},"outputs":[{"output_type":"stream","name":"stdout","text":["(12, 8, False)\n"]}],"source":["observation= env.reset()\n","print(observation)"]},{"cell_type":"markdown","metadata":{"id":"Snkrvn40fyDr"},"source":["## Performing an Action\n","To make the agent act on the environment, use the method `step(action)` on the environment instance. Action has to be one of the valid actions of the environment.\n","\n","In the case of blackjack game, we have hit = 1 and stick = 0.\n","\n","The `step(action)` method returns the following:\n","- A new observation.\n","- The reward of the last action.\n","- Two booleans variable to check if the episode is finished or truncated (stoped for other reasons).\n","- Extra info (it depends on the Gym environment). For blackjack is an empty dict."]},{"cell_type":"code","source":["observation, reward, terminated, truncated, info = env.step(1)\n","print(f'{observation}, {reward}, {terminated}, {truncated}, {info}')"],"metadata":{"id":"hYJTk9D3T5Xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1706029990171,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"quF6aawIgM9X","outputId":"1920b502-209a-479a-dcfc-86142405945d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(39, 8, False), -1.0, True, {'TimeLimit.truncated': False}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["observation, reward, terminated, info = env.step(1)\n","print(f'{observation}, {reward}, {terminated}, {info}')"]},{"cell_type":"markdown","metadata":{"id":"LxPNf5yefJPR"},"source":["## A Random Agent\n","\n","Let's test this environment with a random agent, in which each action (hit or stick) has a probability of 50%."]},{"cell_type":"code","source":["observation, info = env.reset()\n","print(observation)\n","done = False\n","while not done:\n","    action = env.action_space.sample() # Choose a random action from the action space\n","    observation, reward, terminated, truncated, info = env.step(action)\n","\n","    done = terminated or truncated\n","\n","    print(f'{observation}, {reward}, {terminated}, {truncated}, {info}')\n","env.close()"],"metadata":{"id":"oGZMO5QKUEy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1706030042981,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"ramP4th6TNZE","outputId":"f3cb0f4f-521c-4f17-da2f-07a85143b9c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["(11, 2, False)\n","(11, 2, False), 1.0, True, {'TimeLimit.truncated': False}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["observation = env.reset()\n","print(observation)\n","done = False\n","while not done:\n","    action = env.action_space.sample() # Choose a random action from the action space\n","    observation, reward, terminated, info = env.step(action)\n","\n","    done = terminated or truncated\n","\n","    print(f'{observation}, {reward}, {terminated}, {info}')\n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"Uy4nTDpkJV_L"},"source":["## Viewing an environment"]},{"cell_type":"markdown","metadata":{"id":"rVU_lTQMNc-9"},"source":["There are many ways to visualize and manipulate images in google colab/jupyter notebook. One of them is through OpenCV. Just import to the project ``cv2`` to convert the image to BGR (to visualize with OpenCV) and  ``cv2_imshow`` to show the image."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2929,"status":"ok","timestamp":1706030379418,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"jW9v0GEfLxDl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b298ef34-dfe2-4154-85b7-b7435be12a47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running in Google Colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","# Check if we running in Google Colab or Jupyter Notebook\n","import sys\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","if IN_COLAB:\n","    print('Running in Google Colab')\n","    # Connect with Google Drive\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    # This auxiliary function simplifies the visualization of OpenCV Images\n","    from google.colab.patches import cv2_imshow\n","else:\n","    print('Running in Jupyter Notebook')\n","    # This auxiliary function simplifies the visualization of OpenCV Images\n","    def cv2_imshow(img, title=''):\n","        if img.ndim > 2:\n","            img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            # view the image in its natural size\n","            plt.figure(figsize=(img.shape[1], img.shape[0]), dpi=1)\n","            plt.imshow(img)\n","            plt.title(title)\n","            plt.xticks([]), plt.yticks([])\n","            plt.show()\n","        else:\n","            # view the image in its natural size\n","            plt.figure(figsize=(img.shape[1], img.shape[0]), dpi=1)\n","            plt.imshow(img, cmap='gray')\n","            plt.title(title)\n","            plt.xticks([]), plt.yticks([])\n","            plt.show()"]},{"cell_type":"code","source":["env = gym.make('Blackjack-v1', render_mode='rgb_array')\n","observation, _ = env.reset()\n","image = env.render()\n","image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","cv2_imshow(image)"],"metadata":{"id":"slr7cJO6URnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"qPL61NSp-JcF","executionInfo":{"status":"ok","timestamp":1706030243221,"user_tz":-60,"elapsed":436,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"b41783b5-ab93-46d5-ebd1-fcda639a9adf"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=600x500>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlgAAAH0CAIAAABuMsSDAAA36klEQVR4nO3daXhU15no+7eqJJUmECAQAgk4BrvlSRa0OrFNJuNgEuNr++JO0j7pkM4xB9+buU+uHTvHdj92w0kM+EnnaafxDR7TpJ20cwJp52ICnmKSAA4ti8lgARIBBAirNEs1aaj7YRWrtnZVbVUVGln/34d+9l61plrV8ctaWnttl3fVlQIAgKncY90BAADGEoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGC1rGOva+eC/pZV/8+4tm//4q2HswKWwdv7Lm/6+qaN5DDuTgc3/149mTp4Rn/7U9p/sPLxr9PsDABPFcAbCT1Z8NK38u+reHcbWL5G1895s7xj2JDMfnb9wXnFZfPrm3VtGvzMAMIGwNAoAMBqBEABgtOFcGrX63i/X+brbnPPMKy579r516nr38ZoXf//KCHXmcqVHT0Se2v6TYG84Pk9F6Xyd7Te1b7xa+/oodQ4AJoiRCoRban57ytfonOfRu761cvE9+pZAmC7r6K199emEA/7sfet0tlO+swRCALAZqUA4LB658xtTC6Y459l5eJfaFfnUvY+mWO2rtTt31f1pdHry/d/8uLWn/TufXT17ykxr5n9/9zf7Th6w1bDmrx/Iy85V1/+047mzbU1pdRIAkIFxHQi//PHPJdwJadXu71Th5xtL/y7Fak+1NKYbCDPuydNvvNTa037vjXfeMOcaa+YDZ47GB8L7b/liUd4kdb159xYCIQCMgnEdCC8D31z6lXZ/58wi+xN+dy1aOq+47PX3d71bv38s+gUAiCIQjqxk89Q7Fy69c+HSjkAngRAAxta4C4TfvO0r+nprzW+z3Al6uPS6j189a4Et8cdv/DTFJibnFupWDpw+kmyZNOOexPvFu7/xdbUOWXDT717WfyO05U/I+pXvqf5s30BffJ6zbU06258a9g9ZJwCYZtwFwg1/84i+rnh4SbKdkPFR5IFfrE2xiafuffSxu7+trn/8xk+TBcKMexLvn3Y8d+D0kSELPvarp4asysr6levW/S7hXzFXv/jw+DnHDgDGoXEXCK3uqf5swocRF5TMG6LgX322wFuQ7NNrZl85aj3ZWrOjO9TT1tNuS999vEZEjp47kW5PAADDa1wHwh98/qFMCz485CbP0enJw798MuFU8sXfv8JzkwAwHozrQJjM/tNHzrSeU9fHmhqM7cldi27T17uP1xw8czQ+z/TCqTpbXVND3fn6UeocAEwQEzIQ/sub/zpO/u41tj155esb9bXDXzH1dHbtq0+vffWfR6lzADBBjOtA+KeGA8HeUHz6hUQvC/xkxY36+uCZo6d8Z5NVu6BkXtnUmck+vfSeAAAmkHEdCFdu+vshDyzVdj74M32dbHqkPHXvo6kfQ5NBTwAAE8i4DoTJzC2erU/+vNDRPIZvkx8/PQEAZGZCBsLH7v62fqPC2P7da/z0BACQmZEKhOVTS1PJdqol+pe8lotP6ekUESktmp6wVGGiZwRTKahMzitMq2/p9iRjc4tnu1zRVyWfb/8w3Jfg/YJWqfQw1BvW2ToCncPRTQC4rIxUIHzzoZ8PmWftq09XPHSLLdGakuy0lIQyLjhqFQ5p3+P/n377xI3/eLftMJp4qfRw9YsPf2PzY8PXRwC43LjHugMAAIwlAiEAwGgEQgCA0VzeVWmfQA0AwGWDGSEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYLSsse4Axrvyt2aNdRfGqcZbz491F+ysP1ZwSji3Pcc5f7iwN6c7W9/25fZlBdP7b0J4UjinK9ZKcEoot91ryxOaEvJaEsOTe3M6syUdto6FJ/XmdA1Rg+3rj8MfC+MHM0IAgNEIhAAAo7E0CjvbWmjtgW1j1ZNxblHVHdbbMVl8c/ix9tS/d/OCv3QufrDx6A3l1+jbM23n50xNbyV8/5kjC+dcq2/3NtTeNH+RLY8t0VYkFbaOHTpbV1lW4VzE9vXHw4+FcYsZIQDAaMwIETWjptgT9IjIC6+sH+u+TAy2gfryyv9HRPpz+5urW0a66WQ/VlNHs74O9oWstwn5e4PWPO09Hdnu9P6bEAgHh2w0MLgVW5FU2DrWE/IPWUOwd1BPxvDHwvhHIESUJ+TJCnlEZFHFdWPdl4nBNlBq9MQ1Gk2n8mOd9J0pLZrhXM+HXT5rnt6BviGL2DR1NluL/LmlMb4GW6KtSCpsHWvubh2yBtvXt+UfzR8L4x9LowAAozEjRHTDxQv/vm7R1dePdV8mMLVRpfaDw/f9zUMyYtsx+LGGhfqxGlub7lyyStg7YzxmhAAAozEjRGKHvrs2PrFg/tyehtMiUrn+0VHvEVKlfruGSEuh6zXnnCci7S7XFH17IdLT7ipIq60T0u6RWA31EV+By/68jS3xRKTdY2k0FbaOHY+0y1A16K/P/69iSMwIAQBGIxACAIzG0qi59KEkzmfHWFeWzv3HDrU0imQWXX29Gk91lMlw7cKw/VjJnqJTi6LqJ+uuf69yqJNlIo1HKy0ny0xJ/2SZ/jNHKi3HxPQ01FbGnSxjS7QVSYW9YymcLKO/vnVMbLI8npH4sTDhMCMEABiNGSGGYN01UzB/7hj2BMno34iNIfHUmDBEcMCMEABgNGaEGMLsFbfr61BTekdEYrgEp4TUxd6GWhEJhIN/bmnUn9ZHfOqip6FWJ7YHOlXm9v2Hk1Xb6e88l/+f+tYfDryfk5dWxzp6OpsKavRta1dbfHO2xA5/V1N+jaTDHwy8nxvrWEdP59mCPyXLPGXh9WL5+krCIdLDqIcXZiIQYgjFN1frazbLjBX92nf1PqOmjkHHdeqn9Kx7UvbUv6cyH/p/k26G8kfaywY/RzgzzecIu6W9zPIcYUvEV+aabstjS+we3GgqbB3zO9ZQec9KsXx9JeEQ6WHUwwszsTQKADAaM0Lg8tR+6INDP0lwsox184gnP6/yidjmkSJfY8f6lyRug4m1oAx+IEE/C6ESixZeX/m3/91WNm/mjMoHHok1WpBX+XisUds2loSNtq3bIC2hWB8uPj5hezRC3ar/e7bUI98Z4ukRQGFGCAAwGjNCDKH57d36OtI/UDB/XloFPfm5025M8A9z9emMJYuHo49D9CFhK63vvtfvD45CH4ZFaEpYXeyurxGRYG+owRf7Y21DJLqJqas+tgmlI9zdEmkWkfw55SLiPxPdXNP09qsi0lXuFZGAN+/1t18VkYK5ZSISCPo7yr22PLqsStTp6jaY4/KHAyLSpCqMBF+3lFUFg6Fca2Igd1CjTRdbcWi0dYrHlxdrNOR1dwW7dVlbx1TBXpm22zIaCYco1BdWw6iHF2YiEGIITdvf0tf60O3UC+YUT00YCNWnIx2EHFpp/t2ecEvbKPRhWHjbc9TF4gXVErdZZpJru7qoXBDb2dRxqK7cNUNEKr/1oFiXHLcfFJHb1j8qIrXHarOe2yYilevvEpEzbefnfOsTOvNtg5ccVUGdrhLbl1WpLsm3qkXkt1s2l1rqV3kOtvusie99UJP9wnbdqCro3OiC1SvmX3WdTuxeXn2zpVH91ayN1olnsWU0Eg6RHkY9vDATS6MAAKO5vKuuHOs+YGykeNZourqPN5x89uX49IRbIWyfDhfnVhJ+esXqLxZeNX8Y+zDSZ41aZ4QJj03Z/uuXy3c36FvbjhKlIS909xNrdOIFd3Dpk7FPU9nGsuP5Z2bXtejbvQ210Wc2LNtY3t6zY/rWfbrgifzQisfXSNxWF4dG9eMTKnHnpo2zTrQ6lBWRulLP577zPech0sPIWaOGY0YIADAafyPEEKz/bD/3Hzta/rhPkkzgks3DUv/00ueFGfdBz2Ivv7MoEx62qW77/QHryBf5Gq23CZ+X0Lfq/+Yvq6pc9VV966sqlfmLbK20lbiWWBvtGdSorWMJG9WPT6jEScurK+//WnzHnFcdgGSYEQIAjEYgBAAYjaVRJGZbX0p4e/mtIl7GEi459h2rlee2iXWzzPq1MtSS46BtLDvfObTzgE48u2Vz/OKqb88Oa2LvBzXywvb4VhwaLR/8+MT5bW8eeq0mWceAdDEjBAAYjRkhcJlzmGmdzgvdvT72JIP096e7jeXc889IXYtO7KsqtZZV13kzS6yJp/JDKyyNJntIw9rornUbelq26tvzmzbKidb4r8Y2GWSGGSEAwGjMCIEJoC+vT100NJ8Wkc5gtzrhUzkb6VEXBc2xA/ACfUGV7sryiEj++ZMqXd2e8wRFxJ/rrj9/Ut92uiJ9vT06s0rUt6qgTleJ3f1BdRvp6xcRf9hvrVDl6epqV91WiUGvx5pHFXRutD2rL2CtsD8YsZTVX81aYUgKGiyjkXCI9DDq4YWZCITABJAViP5Pdf6MuRJ3skzPxZfWqk+VuqzcMnUayw8SLDnO/8FaEak9Vuv/p38Tkc+sXysipy++hsmaKHErkKqsSixZVvWJ+/+Hvm050uA/GiurErtKXPMfWKILvvdBjbV+3TGHRrPv+8qcqbN04uzl1Td/9XZ9qwraKuwWj3U0Eg6RHkY9vDATS6MAAKPx7yAk5rwBIeE+dZWY7KzRFJu7RBmfLTLsZ42OHw5PKXjycwc9CzH48YlUtrHseP4Za4Vnt2yWvadsrdgen3AX5MVvqHFutGD1Cpk6Syfu3LTx0GsJNvWwWQaZYUYIADAaM0IMwZ3rFZGBYEhE3NnZ4hnqH09uj9vrFZGBUGjoyr3eYehi8mrT6IPbMxI9GS4DngF10R3qERF/OKAuFH+k1/pptMhAn04Xke5gdzSz9OnbUG84WqH0iUjYNaDS1a1EItay0URdlcslIn2uiLXC3v5+a1mV2N/XZ80TDg9q1NaxhI26ekPWRnul31pWd0yXFZEBl3vIIdLDqIcXZiIQYgjX/WPsta6ly28t/thHnPMXLph33ZrBb4J1qHzNg8PRx6TVjmEfhpe7P/rvj0JvgYh05/jVhZLvyrZ+Gi3iztLpInLyH36kLm5c/7hcHJlzeaGPPLFGJ572Naps1jy6rEqUwUuaZbfdsvC+a3Wiq6rUWlYV7CxxLbUkns0PffTxNfGtODS6a92GSMtrutG5dyyrLKvQmW0di379iGvIIdLDqIcXZuLnBwAYjRkhUpLBZhZVJOxrrVu/MbMKo3vlV9xefHO17aOWPTXntm4fsh6HvTMV3/1azvRpQ/bhMpBwR4k+a9R66/J40t3G0rWsSuZcK5bNMvFn0wQuNNvOGk33ZU+2s0a7l1dLWUX8V+M1TMgMM0IAgNFc3lVXjnUfMDbK35qlLmoPbBvBZiKRgVBYRN7/hw1y8S+OcnEPTkKnN/+q61i9iKiC7uwscbtF5Lo13xWR9x9bLyIyMDDQ2ycibm+OiEz6iwVzV/51sgrVTh9bH9zeHLXzYoQsqrpDRBpvPT8stc1+p1Rd/HHPL0Xkw86WksnF+tP3H12vLq5b+12d+M62LdP3nJCLQ13xwFdV+tG1P9KJp73h2775bRGpe+oZEfG5Q5/4n98VkYFgWCfqsqqgrcLf/+rnJSfbReSaR78tIu/9+fDC0r/QZVWed9/7/eTXanTBM97wUkujqqBzo605/dPd+bFGf/lyyakOXVYV1GXVz31qtnf5177tPER6GD928+dF5Nynmpx/BVyuWBrFCHO5rDHPIf5p/eGwCoGKCnixW8tH+rY/PCjRxtZoKn0Yb9z90ZidzmYZTzQ9NCAik4umDsocGhCRLHe/Ss8NDYhItrs/WoO3QCfqsrGtN5YKsyIulU0VzMnOsVYYzZPrtTbq8gxqNNbn5I12hcO5rliF2QODGpWLNUTLurIl7c0yI/hPIox/LI0CAIzGjBCjJPXdMRl82l1Xn8q7gs18cavDjpJ+f8A6bkW+xnS3seQvq6pc9VV966sqlfmLbK20lbiWWBvtCcRvqHFutG3dBmkJ6cRJy6sr7/9afMfYLIPMMCMEABiNGSEwAcRew+Q7IyKdgS5/b1B/GnvHkO+MTgz2hVS6SsxaebtK/90PfygiM1feLiIFF86c3fGuiLT88Ici0hkJXbXydp1n7pc/r4pkWRJ12VP/+r9FxPeH3f0Hj+vE3iPvWcuqgllnjlkbLbxw6uyOfbrRmYM7lrBR90evy5o+Uzfa8s4fQu8d1WV1x1RZ9a1DUthgGY2EQ9QZ7FbDyGuYDEcgBCaA2GuYps8Rh9cwTZ+jE+uyvOo1TNHEix/1bd4uItdUVotI0OvOch0WEWnyi0ifO6jSVZ5YbdPn6ERdts+1XUS6/e3Ffr9OPHX8SHHTBVujTd2+4qZ6nSeQLdmuI7pRlejcaEH5PPUcoWrU391e3BMrqzumyqrR6Ba3dTQSDhGvYYLC0igAwGj8Owi4zDnsKDmdF7p7/Rp9K/396W5jOff8M1LXohP7qkrjz6bJm1liTTyVH1phaTSVlz3tWrehp2Wrvj2/aaOcaI3/amyTQWaYEQIAjMaMELjMOcy0bGeNFvkaO9a/JElmWgnnlLbHJzr2Hz50wD6nPFfikgdiz1TYzhpNeAiq7faK+780Z+osSfL4BGeN4hIxIwQAGI1ACAAwGkujGEfU0tbJ53/eXVefVsHCigVXrPqvI9OpCc9hydGTn2tdTrzgDi5dH1tsTGUby47nn7FWeHbLZtl7ytaKb88O6627IC/dlz0VrF4hU2fpxJ2bNh56LeniKpAuZoQAAKMxI8S4o+d2qfwD38zjQzOQcKZ1Mi90wxNrxLJZJt1tLDOXfapy1bU60fb4RMKzRk/mhxY+via+FYdGbY9PzLrj05VlFck6BqSLGSEAwGjMCDF+lS6/VUQ6D9f5T5+1fZQ/t2zy9RVj0amxEZoWfbfw7voaEQn1hRt8p/WnJyPN6qKrvkYntgc7WyPNIlL4F1eKSPexEyr9/LZXRCRwVZGI+LMGdm57RUQKr14gIoGgv/uqIlseXVYl6nR1G5zk9YcDItJ8VZGI9ERCOy1lVUF/INuaGBzcaPPFVhwa7Sjxtk3L1behoryuYLcua+uYKhh2T9ttGY2EQ6SHUQ8vzEQgxPg145bFItLb1hEfCPPKStWnhvC2Rl8mvHhBtcSdNTrJFT1ss3JBtU7sOFRX7pohIpWrvynWZcN3jsnF5cTaY7VZz20Tkco7viAiZ9rOz1n9CUm25PjOsWgrljXM9mVVqkuyoFpEfrtl8yxL/SrPwU6fNfG9D2qyX9iuG5WLfXZo9MrVK9RZoyqxe3n1zZZGEy6u1g14FltGI+EQ6WHUwwszsTQKADAaM0KMd7NX3D57xe0SN2NAihyeUrCdNXrBHZzzZNKzRhNuY7E9PjFl4fWV96y05fHt2SFb9+lE21mjyV6ra71t2PQz9fqIhI9PsFkGl4gZIQDAaMwIMWEU31w9dKbLVGhKdDfH3oZaEQmEg39uadSf1kd86qKnoVYndoS7WyM+EcmbOUPUtExERNpKXCISuNAsIsH+rLf37NCJoew8dZs3s0TUGaEiumzbxVtVViW2RkI9JS5929Hr3yuiy6rED882Dmo0km1tVHfModHO9t4LIV+sUXew21JWFdRlVSu9rml7LaORcIj0MOrhhZkIhJgw1AKpmbzt0d0cN81fJHGbZQpc29RF5fxFOrHt4NFy13QRqXzgEbEsG1of6Tseap++dZ9OPH3x0O3oYuMD0dpU5iW2Fcit+0Qka1nVJ5beqRN7qkpv+uQKXVY/R3iPpQ91/kGN2tZCEza6a92GqeGQbjR3efXNtyRaLbc0Whfx3GQZjYRDFNss085mGaOxNAoAMBozQsAICc+F6TtWK89tE8tmGetZo6lsY7mw851DOw/oxLNbNlvLJjxrtPeDGnlhe3wrDo2WD3584vy2Nw+9VpOsY0C6mBECAIzGjBAjRf07Pad4asVDX0/26Uj/E96hlbp1/xJuaRuFPow5h5mW7fEJ6e9PeNZowqcU1O2555+RuhadaDtrVF3nzSyxJtoen0jlHRe2s0bPb9ooJ1rjvxqPTyAzzAgBAEYjEAIAjMbSKIZZ9/GGk8++rG/DLW0JV9uUEdrm4NxKwk+vWP3FwqvmD2Mfxg+HJce+Y7XWX6fo4uMTqW9jyV9WVbnqq/q2Y//hQwfsP/e5Epd6sEFvlkn3ZU9X3P+lOVNn6cRJy6sr7/+aDLW4CqSIGSEAwGgu76orx7oPGBvlb81SF7UHtg1LhZf+L/FLnxeOhz4oi6ruEJHGW88PS222H8v2QH3CifX2X79cvrtB3yacaR1sPHpD+TU68YI7uPTJQXMsa9mErex4/pnZdS068bdbNpftPWUr+PaeHeoJenW7/8yRhXNi7/JNttXF2mjBxccnlJ2bNs460RrfMau6Us/nvvM95yHSwzi8PxYmHGaEAACj8TdCYALoz+lXF00dzSLSFuiwftoSCVo/VcJ9IZ0uIk1tH0Yzu0L6tsffo4qoxJ6siEpXtzIQsZaNJuqq3C4RCbr6rBWGenutZVViMOC35ukOdFsbtXUsYaNhf5e10cDgRnXHdFkR6ZVc62gkHKJWf7tteGEmAiEwAXjCHnWhV0StS6PNrtz4xJwsb/HFdBFp/sEmdXGL5Rm+D/NCNz+xRkRK160RkdO+RpXNmkeXVYkyeElz3m2fXnhfbJ3TU1V6y7pYWVUwUOK63ZqYH/r447FGdSsOje5at6G55Q3d6Pzln6ksq9CZbR1TfOIZcoj0rR5emImlUQCA0ZgRApc5h6cUbI9PuDye+HNhxPEpha5lVTLnWp1oO2tUXQcuNNvOGo0/j9S5UdtZo93Lq6WsIv6r8fgEMsOMEABgNGaEwGXOYaZlO2v0gjs458mkZ40mnFPueP4Z6+2UhddX3rPSlse3Z4d6j2DCs0ZTecdFw6af9bgKdOLOTRsPvZZ0TgmkixkhAMBoBEIAgNFYGsWwUStUtrNG0yo7XH3IYInMtLNG1W2/P2A7azTdbSy2s0Z9VaUyf5GtlbYS1xJroz2DGk3lZU9t6zZIS0gn2s4aTba4CqSIGSEAwGjMCDHM8q+Ye/X//JaIfPD9fx4ys8o57HS1qffBU5g/Ej0ZLv1ep5NlfAlPlhkIqXSVWPT1e1X6H//XBhGZ8/V7RaT43Enflnd0Yrs7VPn1e/Xtgm98RRUpsiTqsvU/fklEzr3zhz+++4FO7N+7y1pWFcyt229tdFrjCd+v/2DriXOjuZ/+SNGsct3ohbfeGfjjYV1Wd0yVVd/adrJMwiGKnSzj5WQZoxEIMczcWVnuKZNTzJydcs60pFXtCPVheHlC6Z8s4/ZOd+XGEi9+1NEREpG5864UkZZQV5Yq2xESkYA7qNJVnlhtRTN0oi7b4coVkZZQcHIoVuGRmj2TrWWLZohI/bn6yZZGfYGObEujKtG50YLiGdZG2wLtk4OxsrpjqqwajZa0TpYJcbKM0VgaBQAYjRkhRorauRD2tdat35js09HpQ8LdExXf/VrO9Gmj0Icx57CjxPYcofT3p7uN5dzzz0hdi07sqyqNP5smb2aJNdH2HGGypxWtje5at6GnZau+Pb9po5xojf9qbJNBZpgRAgCMxowQIytn+rSEx1eOpmSPARjCYaZlO2u0yNfYsf4lSTLTSjintD0+0bH/8KED9jnluRKXPBB7psJ21mjCA2tst1fc/6U5U2dJkscnOGsUl4gZIQDAaARCAIDRWBrFKBkPC5LjoQ+jz2HJ0ZOfa11OvOAOLl0fW2xMZRuL7dDts1s2y95TtlZ8e3ZYb90Feem+7Klg9QqZOksn2g7dti2uAuliRggAMBozQsAICWdaJ/NCNzyxRiybZdLdxjJz2acqV12rE22PTyQ8a/Rkfmjh42viW3Fo1Pb4xKw7Pl1ZVpGsY0C6mBECAIzm8q66cqz7gLFR/tYsdVF7YNvY9iRF57ZuF5HZK24f646kZFHVHSLSeOv5Yalt+nvRZ/9ffHGDiATCwbycXP1p/TM/VRcLvvp3OvHUf+7r23dERIoWXi8iHfsPq/Tim6tFpC8QEpGeSKgof7KITFl4vYj0BHoC+z8Qkaw8r86jy6qCOl3l6Z02acbceSLi21MjIl0Snpo3SedRBf0FWXNuqIo1Kr1FeYW6UVXQudGenm6vOzuWZ3rR9PI5uqxKtDXaWzbt6rvudB4iPYz/7b89KCK+v2wd+pfA5YilUUwYLXtqZOIEwuGV2x79b/1N8xeJSFNHs/XMzAJX9J8ylfMX6cS2g0fLXdNFpPJv/7uIqMf7RERtZlHLibXHarOe2yYi6rXyZ9rOz7nu4xK/5KjK7j0VbcWyhtm+rEp1Sb196bdbNpdZ6lcFD/b4rInvfVCT/cJ23ahc7LNDowWrV8y/6jqdp3t5tbVR++LqgbUiUjfguckyGgmHSA+jHl6YiaVRAIDRmBFivDu3dXvLxdUzufjP/+Kbq82cGmbA4SkF21mjF9zBOU8mPWs04TYW2+MTUxZer+Z5tscnZOs+nWg7azTZa3Wttw2bftbjKtCJtscn2CyDS8SMEABgNGaEGL+a394tIoGzTfEfBc42qU9nLFk82t0aC6EpYXWxu75GRIK9oQbfaf1pQyT6stmu+tjUuSPc3RJpFpH8OeUi0vT2q9E85V4R8Z9pFJFgv+f1t1/Vib1ZXnVbMLdMRJrKo385a7Lk0WVVYosr2FPu1bfdEt4dGdBlo3mam9oGNZplbVR3zKHRrg87mkLNsQqzQt2WsqqgLqta6ZVpuy2jkXCIQn1hNYx6eGEmAiHGr6btbyX7yH/6rP/0WTEmEHrbc9TF4gXVErdZZpJru7qoXFCtEzsO1ZW7ZohI5bceFMuy4W2WJcfjofbS7Qd14umLh25Xrr9LRORb0dpU5ttsK5DbD4pI7rKqTyy9UyeeqipdvKRal1WJXSWuex54RN/WBQc1alkLTdrornUbpoZDutHC5dU333K7xBZX74p+Z0ujdeJZbBmNhEOkh1EPL8zE0igAwGjMCDHunHz+59119SlmVv/8L6xYcMWq/zqSnZrwEp4L03esVp7bJpbNMtazRlPZxnJh5zuHdh7QiWe3bLaWTXjWaO8HNfLC9vhWHBotH/z4xPltbx56rSZZx4B0MSMEABiNGSHGkYy3v3fX1Zv50t1UOMy0bI9PSH9/wrNGEz6loG7PPf+M1LXoRNtZo+o6b2aJNdH2+EQq77iwnTV6ftNGOdEa/9V4fAKZYUYIADAagRAAYDSWRoHLnMOSY9+xWuvqYtHFxydS38aSv6yqctVX9W3H/sPqqE9rnnMlLnlgkVg2y6T7sqcr7v/SnKmzdOKk5dWV939NhlpcBVLEjBAAYDRmhMBlzmGm5cnPHfQsxODHJ1LZxmI7a/Tsls3qfRG2s0att+6CvPgNNc6NFqxeIVNn6UTbWaO2OSWQLmaEAACjMSMEJoDevD510dB8WkQ6Qz3+cEB/2hjpVhcFzbEDSAN9AZ0uInnnGtTFuaygvm1rb2nwntaJXVmRE+ca9O1Ab5+1rErUt+7sLBHpdvVZK/T3BqxlVWJPV2fYkqe9vaUh97StJ86NTmpvHrA02uMe1KjumC4rIiF3YYNlNBIOUUegSw2jHl6YiUAITADZgej/VOfPmCtxZ432uAqtnyp1WXnlF9NFJPCjl9XFZyyLn+15oU89sUZE5n9/rVjOGrXm0WVVogxe0uy87dML77tWJ+ZUlX7m+7GyqmC4xPV/WBLb8kO3PB5rVLfi0OiudRsCLX/Qjfbc/pnKsgqd2dax6JgMeKyjkXCI9DDq4YWZWBoFABiNfwdhlKRy8ov6NNlZow6b41M8a9TM02ccnlKwPT7h8njS3cbStaxK5lwrls0y8Y9GBC40284ajT+P1LlR21mj3curpawi/qvx+AQyw4wQAGA0ZoQYYZHIQCj21tOBYEhduHO9yUp4cnLcXq+IDIRCovZHuD36U/WRDPSrnRHq1pPj9D453aj11u3NEZcr3W8zVgY8A+qiO9QjIv5wQF0o/kiv9dNokYE+ld4d7BYRv1zcDxKJ6MRQbygsffo2EIpW67ckxspGItFWLBX2DfRFs7lcItIXiVjLquuI2+UfiPUkGA72Wuu/+Cs4NOoKB6wVhvoHNaq/WjRPpFdEBlzuIYdID6MeXpjJ5V115Vj3AWOj/K1Z6qL2wLaRayXsa61bvzE+PZX1SbXGNXvF7cU3V9s+atlTc27r9rTqsan47tdypk8bsmzGFlXdISKNt54fltpsP5Zts0zC9xBt//XL5bsb9G3Ck6kb8kJ3PxE7//qCO7j0ydinzkuO+jnC2XUt+nZvQ+1N8xfJ4HXOt/fsmL51ny54Ij+04vE1kmSlOvHLniI9M10FYnmOcNaJVoeyIlJX6vncd77nPER6GIf3x8KEw9IoAMBoLI1ipDjvWUh970xCxTdXx08T0+qDnqemvnem5Y/7zv3HjrSKjAcOO0r6/QHbWaPpbmOxnTXqqyqV+YtsrbSVuJZYG+0Z1GgqL3tqW7dBWkI60XbWaLIXCAMpYkYIADAaM0IMs+76U6deeiXFzO8/tkFdXLfmwWHsg6429czzvvKFwgXzkub5hw0iIv0D1tvr/nE4++xswHNxo0oam2X6o5tlQj0iMu+Rr6v0fY99X0QqHvm6iHQ2vO9/+XWd6HMFP/bI/9C31zz6bVVElVWJuuzRtT8SkXNv7tr3ziGdeGrHf1jLqoJNtX+wNtpVf8j/8zdtPXFutOgLS+fNvUo3enrH21lv1uqyumOqbEabZSJD/gS4jBEIMdwG+tVuz5TyppwzvS6kU20080C/U55E+05Hk7s/urWy0FsgIt05fnWh5LuyrZ9Gi7g9Kj2aePGj3NCAiEwumioi+QUFWapsaEBEst0DKl3lidXmLdCJsbKubBHx9Edy+2MVZmV5BpX1FohIljfH2mhufkG2pVGV6NxoQW6BtdHsvh5ro7pjqqzK4464hhwiPYx6eGEmlkYBAEZjRohhcymbFIbrzJeM+3Dy2ehRnA478pO1Nc73zjjsKDmdF7p7fexJBunvT3cby7nnn5G6Fp3YV1UafzZN3swSa+Kp/NAKS6OpvOxp17oNPS1b9e35TRvlRGv8V2ObDDLDjBAAYDRmhMAE4PwaprORLnVhfcdQsC+g0ueu/JyI/O6HP1Tp6tbzpc+ISG7LOZVeom57Os5ueV1EWiyJuqwqqMuqxL7/MsPzpb8SkdOb/7eI+D7osFaorj+c7C6ZVKwL5jUPalQVdG4057abPFm5OjG0oMRz00d02ZaLX81aYcgzyfoapoRDxGuYoBAIgQlgqNcwTbJ+qtRl5ZW5JonItTd8RET6f7ZjUJ4Zc0UkdKw2a/shnee0r7HDtVdEpMmvE3XZWOUz5upEzw1TovW7dohIS9BXbCmr8rQOuKyNBj+oyd4Ra1QVdG40Oyt7ztRZOtH7l8WDyjb5VRFrYne/7TVMCYaI1zBBYWkUAGA0/h0EXOYS7ihRt5783EFHerqDSy1vx01lG8uO55+xVnh2y2bZe8rWim/PDuutuyAv3Zc9FaxeIVNn6cSdmzYeei3Bph42yyAzzAgBAEZjRgg4sc45ij/2kdl3f0aG72GP0ZRwpnUyL3TDE2t0ou2s0YTv8rXdzlz2qcpV10qSxycSnjV6Mj+08PE18a04NGp7fGLWHZ+uLKtI1jEgXcwIAQBGIxACAIzG0iiGjVqh6j7eoE9pif802eLVcC0zptJKwk+vWP3FwqvmO1eb7Hacc1hy7DtWa711eTzpbmPpWlYlc64Vy2aZ+MXVwIVma2LvBzXpvuypfPWK+Vddp2+7l1dLWUX8V+M1TMgMM0IAgNFc3lVXjnUfMDbK35qlLmoPbBuJ+tU/zHOKp1Y89PVkn4701Mqhlbp1/xJuaUuxD9FN/PPn9jScjv80YQ2Lqu4QkcZbz6fZ5cRsP5btgfqEp55u//XL5bsb4jtpnTA15IXufiJ27OcFd3Dpk7FPnWda+vGJ2XUt+nZvQ+1N8xfJ4JF/e8+O6Vv36YIn8kMrHl8jSX6dhI1eiPTMdBXoxJ2bNs460epQVkTqSj2f+873nIdID+Pw/liYcJgRAgCMxt8IMVJKb79VRDz5uQ6fjk4fEppxy839/mCK9RTMnyci3pLpkypiKyhddfWX2L3UhaZF34C4u75GREJ94QZfbG56MtIc7VJ9jU5sD3a2RppFpPAvrhSR89uib0sOXFUkIt3HToiIv8+zc9srOjHsmaRuC69eICLNVxWpIucteXRZldjqCQevKtK3XTmR3ZEBXVYltnT4OpM3qjvm0Gj7mY4LgeZYozm91rKqoC6rWgm7p+22jEbCIdLDqIcXZiIQYqTMWLI4409HoQ/TbvzL1OvpaTglIrmzSqwVNm1/61L6lhZvq1ddLF5QLXFLo5Nc29VF5YJqndhxqK7cNUNEKld/U5IsOR4Pt89655hOPO1r7Fj/kohU3vEFEZGLtSV+XO+dYyKSt6zqE0vv1InhqtLFt1XrstG9LSWuux94RN/WhQY1GutY8kZ3rdswVb0M+Z1jIjJpefXNt9wey6MKDm60bsCz2DIaCYdID6MeXpiJpVEAgNGYEQKXpymVV1f+n1+UuE0uCZ8usO1Jcchjc2HnO4d2HtC3HfsPHzpgz6Yfn3Cu0CFPONIjrgKdeH7bm4deq0lWMPoYT/178bUBCTEjBAAYjRkhMLSCK+aKiAxEWnb/pz1xVISmRHdz7G2oFZFAOPjnlkb9aX3Epy56Gmp1YnugU2U+V+JKVq0/e+rxXksrnsLO/vQ6FvQWHw8N6Nv+3JLjwYgtT593xnHLZpRAzrTjYXseZ+HsyZ29sVYCgxu1UYPQ5u/YaxmNhEOkh1EPL8xEIASG1nPytIiIS1r2/OdQeUeEtz26m0M9pWfbLFPgij4JWjl/kU7cU/+eyiwPxBJtDjYevaH8Gn17pu28ev9t6vafObJwzrX6Vj9HaGVLtBVJha1jh87WqUO3HcS+vogkGaLYZpl2NssYjaVRAIDRmBECqcqdNXP+//1lfTt+zrRMdlwnhDFBCpgRAgCMxozQXPpkRXXQ4gv/vm7R1dePaY/Gu+D5C0POAms/OHzf3zwkw31wZfyPZf0boWZ9RL0h0lLoes252hORdpdrir69EOlptzylkIoT0u6RWA31EZ/+a1yyxBORdo+l0VTYOnY80i5D1aC/vsNcsK+/n1NGIcwIAQCGIxACAIzG0igwtIm11UIfrVK5YIjzVCONRystj09MSf/xif4zRyotz0L0NNRWxj0+YUu0FUmFvWMpPD6RytcHFGaEAACjMSNEdKfAl//ugaygR0bsPb2XPbXtoi+3v+nWD0euFX6sYTE6PxYmCmaEAACjMSNEVL+3XyIiIrV171vTF1VcNzYdGvdsA9Xn7Rc1jCNP/1iNrU3W9CyPR18He0NNHc3O9fh7g9Y87T0d2e70/psQCA+qIdiXoNHA4Fb8g4ukwtaxnpB/yBpsX7+vf9DvMpo/FsY/AiGimqtb1MV9X/iuNZ3Ft2RsAzWai2z6x7pzySpruvXHOuk7k/BZQ6sPu3zWPL0DfUMWsWnqHHTq6Z9bGuNrsCXaiqTC1rHm7tYha7B9fbUWGusDK6KwYGkUAGA0l3fVlWPdB4xr5W+lt5/eHOPwOBLrjxWcEs5tz3HOHy7szenO1rd9uX1ZwfRWicKTwjldsVaCU0K5cW9yCE0JWV/vEJ7cm9OZLemwdSw8qTena4gabF9/HP5YGD+YEQIAjMaMEABgNGaEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABgtaxjr2vngv6WVf/PuLZv/+CuHSr686e+bOpqHoWcAACQxnIHwkxUfTSv/rrp3nSvxZnsvtU8AADhiaRQAYDQCIQDAaMO5NGr1vV+u83W3OeeZV1z27H3r1PXu4zUv/v6VEeoMAADJjFQg3FLz21O+Ruc8j971rZWL79G3BEIAwOgbqUA4jJ6699EUc75au3NX3Z8cin//Nz9u7WmPL3jvjXf+1RVV6nrn4V07D++yZXjkzm9MLZji3LouGN/idz67evaUmdbM//7ub/adPOBcIQBgFEyAQPiNpX+XYs5TLY3xgdBa/Ok3XkoYCD993cf13LTd3xkfCL/88c/NKy5zbl0XjG/x3hvvvGHONdbMB84cJRACwHgwUoHwm0u/0u7vHDLb2lefVhcHzxwdoZ6MLTUOM4tm2NLvWrR0XnHZ6+/verd+/1j0CwAQNVKBMJVp3NpXn1776j+PUAfGiWTjcOfCpXcuXNoR6CQQAsDYmgBLoz9+46cp5pycW/jN276irg+cPhK/TJoWXZWIbK35bZY7wVgtve7jV89aMGRVv3j3N76u1gwKAgBG2gQIhA/8Ym2KOZ+699HH7v62uv7xGz+9xEC44W8e0dcVDy9JuAn22fvWpRLP/mnHcwdOH8mgIABgpI1UINxas6M71OOcJ4O/C97zV58t8BYk+/Sa2VemW2Gq7VZ/NuFjkQtK5jkXVOPQFrdDZ/fxGhE5eu7EMHUQAJChkQqED//yySGfI8zADz7/8JC7N0fCDz7/UGYFk43Di79/hecmAWA8mABLo+PZ/tNHzrSeU9fHmhrGtjMAgAwQCC/Jv7z5r/FvkgIATCATIBB+suJGfX3wzNFTvrPJci4omVc2daYt0bplpmrONQlXVkvjnvOz+VPDgWBvKD79Aq9LBIAJbgIEwp0P/kxfJ9u9qTx176Pxz+0t2/C3+rpu3e8y+xPjyk1/PxJ/8gQAjLkJEAjHs7nFs/UZpBc6mpuYIALAREMgvCSP3f1tfUipCQflAMDlZwIEwlMtsT8KlhZNd8g5Oa/QuaqzbU0J06cXTi3w5mfQbmHyhxoBABPCBAiEFQ/doq8z/iOfcuuT9yZMf/a+ddY3Iw57uwCAccs91h0AAGAsEQgBAEYjEAIAjObyrhqpg6rHieBzx4fMs/rFhzkgBgDMxIwQAGA0AiEAwGgEQgCA0SbAc4SXqOLhJUPmaUn00l0AgAku/0DIYdkAAAcsjQIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADBa1lh3ALhsVcxaMHPy9IyL/6lhf7A3NIz9AZAQgRAYKQ/cfv/KxfdkXLzi4SWnfI3D2B8ACbE0CgAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAaJ8sAmatb9zuHT5/a/pO1rz6dceWb7//RzKKkJ7T9+I2Xnn79pYwrB6ARCIHMzSsuc/g02Bu+lDPSZhZNd6i/KG9yxjUDsGJpFABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEbj7RNA5n6z/w2HT6cXTr1r0W0ZV777eM3BM0eTfXqsqSHjmgFYubyrrhzrPgCXp2fvW7dy8T0ZF694eMmlvMUJQIpYGgUAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjSPWgMxdePo9h08ffuXJB3/xvzKu/K2Hf1E2tTTZp09t/8mG136SceUANAIhkLmivEkOn/YN9Lf7OzOuvMCb71C/N8ubcc0ArFgaBQAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNF4+wSQuc27tzh8Wlo0feXH/jrjyl8//Htvdk6yTw+eOZpxzQCsXN5VV451H4DL07P3rVu5+J6Mi1c8vOSUr3EY+wMgIZZGAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEbjZBkAgNGYEQIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGA0AiEAwGgEQgCA0QiEAACjEQgBAEYjEAIAjEYgBAAYjUAIADAagRAAYDQCIQDAaARCAIDRCIQAAKMRCAEARiMQAgCMRiAEABiNQAgAMBqBEABgNAIhAMBoBEIAgNEIhAAAoxEIAQBGIxACAIxGIAQAGI1ACAAwGoEQAGC0/x9vo1+rJC+b2QAAAABJRU5ErkJggg==\n"},"metadata":{}}],"source":["import numpy as np\n","import cv2\n","env = gym.make('Blackjack-v1', render_mode='rgb_array')\n","observation = env.reset()\n","image_list = env.render(mode='rgb_array')\n","image = image_list[0]\n","image = cv2.cvtColor(np.array(image, dtype=np.uint8), cv2.COLOR_RGB2BGR)\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"lgJcY8b6-JcG"},"source":["Much nicer :)\n","\n","Let's try a second environment Acrobot"]},{"cell_type":"code","source":["env = gym.make('Acrobot-v1', render_mode = 'rgb_array')\n","observation, _ = env.reset()\n","image = env.render()\n","image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","cv2_imshow(image)"],"metadata":{"id":"hJUTDpoxU8J1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706030288780,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"G0NphR6BMA_q","outputId":"4e0fc5c1-79c9-49a1-893b-afbb4398ba70"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=500x500>"],"image/png":"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\n"},"metadata":{}}],"source":["env = gym.make('Acrobot-v1', render_mode = 'rgb_array')\n","observation = env.reset()\n","image_list = env.render(mode='rgb_array')\n","image = image_list[0]\n","image = cv2.cvtColor(np.array(image, dtype=np.uint8), cv2.COLOR_RGB2BGR)\n","cv2_imshow(image)"]},{"cell_type":"markdown","metadata":{"id":"UZl26BYhPXV4"},"source":["## Helper to Save Videos\n","We are going to define a function that generates a video out of a list of frames. We will use this helpers in all notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qf_kj7VICbMv"},"outputs":[],"source":["# Video management imports\n","import cv2\n","\n","# Helper functions to save videos and images\n","def save_video(img_array, path='/content/drive/MyDrive/Master de Datos/Smart Robotics/Videos OpenAI Gym'):\n","  height, width, layers = img_array[0].shape\n","  size = (width, height)\n","  out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'AVC1'), 15, size)\n","  for i in range(len(img_array)):\n","    bgr_img = cv2.cvtColor(img_array[i], cv2.COLOR_RGB2BGR)\n","    out.write(bgr_img)\n","  out.release()\n","  print('Video saved.')\n","\n","def save_images(img_array, path='./images'):\n","  for i, image in enumerate(img_array):\n","    bgr_img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","    cv2.imwrite(path + '/img_' + str(i) + '.jpg', bgr_img)"]},{"cell_type":"code","source":["def save_video(img_array, path='/content/drive/MyDrive/Master de Datos/Smart Robotics/Videos OpenAI Gym/'):\n","    # Ensure img_array[0] is a NumPy array\n","    if isinstance(img_array[0], list):\n","        img_array[0] = np.array(img_array[0][0])  # Take the first image from the list\n","\n","    height, width, _ = img_array[0].shape\n","    size = (width, height)\n","    out = cv2.VideoWriter(path, cv2.VideoWriter_fourcc(*'AVC1'), 15, size)\n","\n","    for img in img_array:\n","        if isinstance(img, list):\n","            img = np.array(img[0])  # Take the first image from the list\n","        bgr_img = cv2.cvtColor(np.array(img, dtype=np.uint8), cv2.COLOR_RGB2BGR)\n","        out.write(bgr_img)\n","\n","    out.release()\n","    print('Video saved.')"],"metadata":{"id":"MQZM85coWh5W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8OaW3AD6-JcJ"},"source":["Once we have defined this function, we can run again an episode loop. In this case, we can simply store the image generated by the environment into a list. We will use this list as frames for image generation."]},{"cell_type":"code","source":["# The same random agent but saving an image array\n","observation, info = env.reset()\n","done = False\n","img_array = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","\n","    image = env.render()\n","    img_array.append(image)\n","env.close()"],"metadata":{"id":"4h6GxAq-VoSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYxWOq7qCx2f"},"outputs":[],"source":["# The same random agent but saving an image array\n","observation = env.reset()\n","done = False\n","img_array = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, info = env.step(action)\n","    done = terminated\n","\n","    image = env.render()\n","    img_array.append(image)\n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"xNNin2QV-JcK"},"source":["We can call save_video to store the file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1706030793927,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"},"user_tz":-60},"id":"uW-77aC0DZi4","outputId":"ca225d54-7b1c-4919-98f9-feaa6a8f3c4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Video saved.\n"]}],"source":["# Remember to create a 'video' folder\n","save_video(img_array)"]},{"cell_type":"markdown","metadata":{"id":"p4O_SwXc-JcL"},"source":["Finally, we can embed the video in our notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WDX9GGvHCrT","colab":{"base_uri":"https://localhost:8080/","height":172},"executionInfo":{"status":"ok","timestamp":1706030826325,"user_tz":-60,"elapsed":6,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"52a675c4-4c9f-4739-af7e-212c6c0583e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video controls  >\n"," <source src=\"data:None;base64,./video/test.mp4\" type=\"None\">\n"," Your browser does not support the video tag.\n"," </video>"]},"metadata":{},"execution_count":74}],"source":["from IPython.display import Video\n","Video('./video/test.mp4', embed=True)"]},{"cell_type":"markdown","metadata":{"id":"dSL2OvTn-JcM"},"source":["Let's explore the Acrobot environment. Let's start by analyzing its observation space:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GlvlWfpQ-JcN","executionInfo":{"status":"ok","timestamp":1706030844560,"user_tz":-60,"elapsed":511,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"30aeca98-c9d1-4ba4-8bf5-32f8c2007106"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box([ -1.        -1.        -1.        -1.       -12.566371 -28.274334], [ 1.        1.        1.        1.       12.566371 28.274334], (6,), float32)"]},"metadata":{},"execution_count":75}],"source":["env.observation_space"]},{"cell_type":"markdown","metadata":{"id":"5Keepfns-Jcv"},"source":["In this case we have 6 continuous observations (float32). The first vector indicates the lower limit values for this variables, while the second indicated the upper limits."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tCU9LxZz-Jcw","executionInfo":{"status":"ok","timestamp":1706030846564,"user_tz":-60,"elapsed":2,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"0d476d94-44fd-464e-8955-553be39072e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(3)"]},"metadata":{},"execution_count":76}],"source":["env.action_space"]},{"cell_type":"markdown","metadata":{"id":"Nnt--lh8-Jcw"},"source":["In this case we have 3 discrete actions that we can perform.\n","\n","Let's try another environment: Pendulum"]},{"cell_type":"code","source":["env = gym.make(\"Pendulum-v1\", render_mode='rgb_array')\n","\n","# Let's get some info about the observation and action spaces\n","print(env.observation_space)\n","print(env.action_space)\n","\n","# A random Pendulum\n","observation, info= env.reset()\n","done = False\n","img_array = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","\n","    image = env.render()\n","    img_array.append(image)\n","env.close()"],"metadata":{"id":"VmLcokndXUjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pc0MxRMo-Jcx","executionInfo":{"status":"ok","timestamp":1706030872661,"user_tz":-60,"elapsed":1759,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"b119e57c-1c8e-4cf6-a598-e597cef326ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)\n","Box(-2.0, 2.0, (1,), float32)\n"]}],"source":["env = gym.make(\"Pendulum-v1\", render_mode='rgb_array')\n","\n","# Let's get some info about the observation and action spaces\n","print(env.observation_space)\n","print(env.action_space)\n","\n","# A random Pendulum\n","observation = env.reset()\n","done = False\n","img_array = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, info = env.step(action)\n","    done = terminated\n","\n","    image = env.render()\n","    img_array.append(image)\n","env.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQ1NLg3q-Jcx","executionInfo":{"status":"ok","timestamp":1706030897568,"user_tz":-60,"elapsed":432,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"1c1cba90-9f63-45a5-e606-cce75aa037a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Video saved.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}],"source":["save_video(img_array, path='video/gym_pendulum.mp4')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"wJ29fI0z-Jcy","executionInfo":{"status":"ok","timestamp":1706030917747,"user_tz":-60,"elapsed":402,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"9248c157-2cb4-45fa-d027-962045db9974"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video controls  >\n"," <source src=\"data:None;base64,./video/gym_pendulum.mp4\" type=\"None\">\n"," Your browser does not support the video tag.\n"," </video>"]},"metadata":{},"execution_count":82}],"source":["Video('./video/gym_pendulum.mp4', embed=True)"]},{"cell_type":"markdown","metadata":{"id":"prM6kFcr-Jcz"},"source":["\n","As we can see above Pendulum has both a continuous action and observation space. The observation space in the position of pendulum:\n","- x, y coordinates of the end of the pendulum in meters.\n","- the angle in radians\n","\n","The action is a torque tau in Nm.\n","\n","# Exercise\n","\n","Can we solve an environment such as Pendulum with Value iteration? Why?\n","\n","\n","\n","\n","Although Value Iteration is a powerful algorithm for discrete MDPs, it is not directly applicable to continuous state and action spaces, such as those found in the Pendulum environment. Continuous state and action problems often require more advanced algorithms designed to handle such spaces.\n","\n","# Other Environments\n","\n","Finally let's try another environment: Reacher. Reacher as many RL is defined using a simulation. In this case the simulation is based on the Mujoco library. This library provides primitives to simulate complex mechanisms in a physically realistic way."]},{"cell_type":"code","source":["env = gym.make(\"Reacher-v4\", render_mode='rgb_array')\n","\n","# Let's get some info about the observation and action spaces\n","print(env.observation_space)\n","print(env.action_space)\n","\n","# A random Pendulum\n","observation, info= env.reset()\n","done = False\n","img_array = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","\n","    image = env.render()\n","    img_array.append(image)\n","env.close()\n","\n","save_video(img_array, path='video/gym_humanoid.mp4')\n","Video('./video/gym_humanoid.mp4', embed=True)"],"metadata":{"id":"0rpuHWCfXyH1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8PIO9xoi-Jc0"},"source":["## Custom Environment\n","\n","One of the advantages of using Gymnasium and RL-based algorithms based on the OpenAI's Gym API is that we can easily create our own environment."]},{"cell_type":"markdown","metadata":{"id":"eioY98a_-Jc1"},"source":["### Example 1: Two Arm Bandit\n","\n","This environment has a limited set of states and our agent can only move right or left."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8I9jJD50-Jc1"},"outputs":[],"source":["from gym import spaces\n","import numpy as np\n","\n","class TwoArmedBanditEnv(gym.Env):\n","    metadata = {'render.modes': ['human']}\n","\n","    def __init__(self):\n","        super(TwoArmedBanditEnv, self).__init__()\n","\n","        self.reward_range = (-100.0, 100.0)\n","        self.action_space = spaces.Discrete(2) # Two actions: left and right\n","        self.observation_space = spaces.Discrete(5) # 5 posible observation values\n","\n","        self.rewards = np.array([+100, -10, 0, -5, -100]) # The rewars of each state, usually computed\n","\n","    def reset(self):\n","        self.current_pos = 2 # usually randomized\n","        observations = (self.current_pos)\n","        return observations, None\n","\n","    def step(self, action):\n","        if action == 0: # Move Left\n","            self.current_pos -= 1\n","        if action == 1: # Move right\n","            self.current_pos += 1\n","        terminated = ((self.current_pos == 0) or (self.current_pos == 4)) # Positions 0 and 4 are final\n","        truncated = False\n","        observations = (self.current_pos)\n","        reward = self.rewards[self.current_pos]\n","        return observations, reward, terminated, truncated, None\n","\n","    def render(self):\n","        output = ['_','_','_', '_', '_']\n","        output[self.current_pos]='*'\n","        print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_blMAluY-Jc2"},"outputs":[],"source":["#from gymnasium.envs.registration import register\n","\n","#register(\n","#    id='TwoArmedBandit-v0',\n","#    entry_point='path.to.module:TwoArmedBanditEnv',\n","#)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSiDzOaP-Jc2","executionInfo":{"status":"ok","timestamp":1706032834178,"user_tz":-60,"elapsed":543,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"ff246384-14a3-4d71-bf21-c5c4179cb2f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Discrete(5)\n","Discrete(2)\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Rewards: [-5, 0, -10, 0, -10, 100], accumulated: 75\n"]}],"source":["#env = gym.make(\"TwoArmedBandit-v0\", render_mode='human')\n","env = TwoArmedBanditEnv()\n","\n","# Let's get some info about the observation and action spaces\n","print(env.observation_space)\n","print(env.action_space)\n","\n","# A random Pendulum\n","observation, info = env.reset()\n","done = False\n","rewards = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","    rewards.append(reward)\n","    env.render()\n","\n","env.close()\n","print(f\"Rewards: {rewards}, accumulated: {sum(rewards)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"TRVrTR6s-Jc3"},"source":["### Exercise\n","\n","Run the TwoArmBandit environment in a loop several times (100) and store some statistics: number of steps and accumulated reward for each step. In each iteration compute the accumulated reward for each state in reverse and add it to the cell:\n","\n","For example if the output is:\n","```txt\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","```\n","Rewards: [-10, 100], accumulated: 90\n","We have:\n","-    accum_reward[0] += 100 #(for the first cell or #0)\n","-    accum_reward[1] += 90 #( 100 -10 for cell #1)\n","\n"]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","\n","# Define the environment\n","env = TwoArmedBanditEnv()\n","\n","# Number of episodes\n","num_episodes = 100\n","\n","# Initialize an array to store accumulated rewards for each state\n","num_states = env.observation_space.n\n","accum_rewards = np.zeros(num_states)\n","\n","for episode in range(1, num_episodes + 1):\n","    # Reset the environment for a new episode\n","    observation, info = env.reset()\n","    done = False\n","    rewards = []\n","\n","    while not done:\n","        # Choose a random action\n","        action = env.action_space.sample()\n","\n","        # Take a step in the environment\n","        observation, reward, terminated, truncated, info = env.step(action)\n","        done = terminated or truncated\n","\n","        # Accumulate rewards for each time step\n","        rewards.append(reward)\n","        env.render()\n","\n","    # Calculate the accumulated reward for each state in reverse order\n","    for i, r in enumerate(reversed(rewards)):\n","        accum_rewards[observation] += r  # Adjust the index to match the number of states\n","\n","    # Print the observation for the episode\n","    print(f'Episode {episode}: Observation: {observation}')\n","\n","    # Print the rewards and accumulated reward\n","    print(f'Rewards: {rewards}, accumulated: {sum(rewards)}\\n')\n","\n","# Print the accumulated rewards for each state\n","print(f'Accumulated rewards for each state: {accum_rewards}')\n","\n","# Close the environment\n","env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1Hrxw7zgK9U","executionInfo":{"status":"ok","timestamp":1706033212968,"user_tz":-60,"elapsed":501,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"0335ed2e-6024-4f7e-8872-10c2c4da3666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 1: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 2: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 3: Observation: 0\n","Rewards: [-10, 0, -10, 0, -10, 100], accumulated: 70\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 4: Observation: 4\n","Rewards: [-5, 0, -5, 0, -10, 0, -5, 0, -5, -100], accumulated: -130\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 5: Observation: 4\n","Rewards: [-10, 0, -10, 0, -5, -100], accumulated: -125\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 6: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 7: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 8: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 9: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 10: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 11: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 12: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 13: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 14: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 15: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 16: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 17: Observation: 0\n","Rewards: [-10, 0, -10, 0, -10, 100], accumulated: 70\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 18: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 19: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 20: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 21: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 22: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 23: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 24: Observation: 0\n","Rewards: [-5, 0, -5, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 25: Observation: 4\n","Rewards: [-10, 0, -10, 0, -5, 0, -5, 0, -5, -100], accumulated: -135\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 26: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 27: Observation: 0\n","Rewards: [-10, 0, -5, 0, -10, 100], accumulated: 75\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 28: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 29: Observation: 0\n","Rewards: [-10, 0, -5, 0, -5, 0, -10, 0, -10, 0, -10, 0, -10, 100], accumulated: 40\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 30: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 31: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 32: Observation: 4\n","Rewards: [-10, 0, -5, 0, -10, 0, -5, -100], accumulated: -130\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 33: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 34: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 35: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 36: Observation: 4\n","Rewards: [-10, 0, -10, 0, -5, -100], accumulated: -125\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 37: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 38: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 39: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 40: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 41: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 42: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 43: Observation: 4\n","Rewards: [-5, 0, -5, 0, -5, -100], accumulated: -115\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 44: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 45: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 46: Observation: 0\n","Rewards: [-10, 0, -10, 0, -10, 100], accumulated: 70\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 47: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 48: Observation: 4\n","Rewards: [-5, 0, -5, -100], accumulated: -110\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 49: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 50: Observation: 0\n","Rewards: [-5, 0, -5, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 51: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 52: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 53: Observation: 0\n","Rewards: [-10, 0, -5, 0, -10, 100], accumulated: 75\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 54: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 55: Observation: 4\n","Rewards: [-5, 0, -5, -100], accumulated: -110\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 56: Observation: 0\n","Rewards: [-5, 0, -10, 0, -10, 100], accumulated: 75\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 57: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 58: Observation: 0\n","Rewards: [-10, 0, -5, 0, -5, 0, -10, 100], accumulated: 70\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 59: Observation: 4\n","Rewards: [-10, 0, -5, -100], accumulated: -115\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 60: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 61: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 62: Observation: 4\n","Rewards: [-10, 0, -5, -100], accumulated: -115\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 63: Observation: 4\n","Rewards: [-5, 0, -5, 0, -10, 0, -5, -100], accumulated: -125\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 64: Observation: 4\n","Rewards: [-10, 0, -5, -100], accumulated: -115\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 65: Observation: 4\n","Rewards: [-10, 0, -5, 0, -5, 0, -10, 0, -5, 0, -10, 0, -10, 0, -10, 0, -5, -100], accumulated: -170\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 66: Observation: 4\n","Rewards: [-5, 0, -10, 0, -5, 0, -5, -100], accumulated: -125\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 67: Observation: 4\n","Rewards: [-5, 0, -5, 0, -5, -100], accumulated: -115\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 68: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 69: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 70: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 71: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 72: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 73: Observation: 4\n","Rewards: [-5, 0, -5, -100], accumulated: -110\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 74: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 75: Observation: 4\n","Rewards: [-10, 0, -10, 0, -5, -100], accumulated: -125\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 76: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 77: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 78: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 79: Observation: 0\n","Rewards: [-5, 0, -10, 0, -10, 100], accumulated: 75\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 80: Observation: 4\n","Rewards: [-10, 0, -5, 0, -10, 0, -5, -100], accumulated: -130\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 81: Observation: 4\n","Rewards: [-10, 0, -5, -100], accumulated: -115\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 82: Observation: 4\n","Rewards: [-10, 0, -5, -100], accumulated: -115\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 83: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 84: Observation: 4\n","Rewards: [-10, 0, -5, -100], accumulated: -115\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 85: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 86: Observation: 4\n","Rewards: [-5, 0, -5, -100], accumulated: -110\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 87: Observation: 0\n","Rewards: [-5, 0, -10, 100], accumulated: 85\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 88: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 89: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 90: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 91: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 92: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 93: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 94: Observation: 4\n","Rewards: [-5, 0, -5, 0, -5, -100], accumulated: -115\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 95: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 96: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 97: Observation: 4\n","Rewards: [-5, -100], accumulated: -105\n","\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 98: Observation: 0\n","Rewards: [-10, 100], accumulated: 90\n","\n","['_', '*', '_', '_', '_']\n","['_', '_', '*', '_', '_']\n","['_', '*', '_', '_', '_']\n","['*', '_', '_', '_', '_']\n","Episode 99: Observation: 0\n","Rewards: [-10, 0, -10, 100], accumulated: 80\n","\n","['_', '_', '_', '*', '_']\n","['_', '_', '*', '_', '_']\n","['_', '_', '_', '*', '_']\n","['_', '_', '_', '_', '*']\n","Episode 100: Observation: 4\n","Rewards: [-5, 0, -5, -100], accumulated: -110\n","\n","Accumulated rewards for each state: [ 4995.     0.     0.     0. -4585.]\n"]}]},{"cell_type":"markdown","source":["## Example 2: BallEnv"],"metadata":{"id":"XaHRL4aCgJ3M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-oGUAch-Jc4"},"outputs":[],"source":["import math\n","\n","class BallEnv(gym.Env):\n","\n","    metadata = {'render.modes': ['rgb_array']}\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.reward_range = (-1.0, 1.0)\n","        self.action_space = spaces.Box(low=np.array([0]), high=np.array([2]), dtype=np.float32)\n","        self.observation_space = spaces.Box(low=np.array([0]), high=np.array([10]), dtype=np.float32)\n","\n","        self.BALL_RADIUS = 0.1\n","\n","        self.y = 10\n","\n","\n","    def reset(self, seed=None, options=None):\n","        # Reset the state of the environment to an initial state\n","        self.y = np.random.rand()*10\n","\n","        return np.array([self.y]), False\n","\n","    def step(self, action):\n","        self.y += action[0] # We simply add the action\n","        self.y -= 1      # And decay to move to the ground as if falling\n","\n","        terminated = False\n","        truncated = False\n","        reward = - math.fabs(self.y-10)\n","\n","        if self.y > 20 or self.y < 0:\n","            terminated = True\n","\n","        info = {}\n","\n","        return np.array([self.y]), reward, terminated, truncated, info\n","\n","    def render(self):\n","        SCALE = 20\n","        def t(x,y):\n","            return (320 + int(SCALE*x), 470 - int(SCALE*y))\n","\n","        image = np.ones((480, 640, 3), dtype=np.uint8 )*255\n","\n","        cv2.circle(image, t(0, self.y), int(SCALE*self.BALL_RADIUS), (0, 0, 255))\n","        cv2.line(image, t(-10, 0), t(10, 0), (0.2, 0, 0), 2)\n","        cv2.line(image, t(-1, 10), t(1, 10), (0.2, 0, 0), 1)\n","        cv2.line(image, t(-1, 20), t(1, 20), (0.2, 0, 0), 2)\n","\n","        return image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVIjG3CG-Jc5","executionInfo":{"status":"ok","timestamp":1706031478402,"user_tz":-60,"elapsed":3,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"220b45d7-6b66-4409-a04e-4eb53406344b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Box(0.0, 10.0, (1,), float32)\n","Box(0.0, 2.0, (1,), float32)\n","Rewards: [-9.541294906153583, -10.264265749468708], accumulated: -19.80556065562229\n","Video saved.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"]}],"source":["env = BallEnv()\n","\n","# Let's get some info about the observation and action spaces\n","print(env.observation_space)\n","print(env.action_space)\n","\n","# A random Pendulum\n","observation, info = env.reset()\n","done = False\n","rewards = []\n","imgs = []\n","while not done:\n","    action = env.action_space.sample() # Choose a random action\n","    observation, reward, terminated, truncated, info = env.step(action)\n","    done = terminated or truncated\n","    rewards.append(reward)\n","    img = env.render()\n","    imgs.append(img)\n","\n","env.close()\n","print(f\"Rewards: {rewards}, accumulated: {sum(rewards)}\")\n","\n","save_video(imgs, path='./video/random_ballenv.mp4')"]},{"cell_type":"markdown","metadata":{"id":"pLIUhhkQ-Jc6"},"source":["### Exercise: Find Home\n","\n","Develop an environment where an agent, a robot, can move freely. The agent can move from (-10, 10) in X and Y axis. In every episode the agent will be spawn at a random position in the environment. The episode ends if the agent reaches the center of the environment, that is if the distance to the center is below 1.0.\n","\n","Create this environment and test it with a random agent. To avoid infinite episodes end the episode after 200 steps."]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","class FreeMoveEnv(gym.Env):\n","    def __init__(self):\n","        super(FreeMoveEnv, self).__init__()\n","        self.episode_count = 1\n","\n","        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(2,), dtype=np.float32)\n","        self.observation_space = gym.spaces.Box(low=-10, high=10, shape=(2,), dtype=np.float32)\n","\n","        self.max_steps = 200\n","        self.current_step = 0\n","        self.agent_positions = np.empty((0, 2))\n","\n","        self.epsilon = 0.2\n","\n","    def reset(self):\n","        self.current_step = 0\n","        initial_observation = np.random.uniform(low=-10, high=10, size=(2,))\n","        self.agent_positions = np.array([initial_observation])\n","        return initial_observation\n","\n","    def step(self, action):\n","        self.current_step += 1\n","\n","        # Estrategia epsilon-greedy\n","        if np.random.rand() < self.epsilon:\n","            action = self.action_space.sample()  # Selecciona una accin aleatoria\n","\n","        observation = self.agent_positions[-1] + action\n","        distance_to_center = np.linalg.norm(observation)\n","\n","        terminated = False\n","        truncated = False\n","        reward = -distance_to_center  # Negative reward based on distance to center\n","\n","        if distance_to_center < 1.0 or self.current_step >= self.max_steps:\n","            terminated = True\n","            truncated = self.current_step >= self.max_steps\n","\n","        self.agent_positions = np.vstack([self.agent_positions, observation])\n","\n","        info = {}\n","\n","        # Imprime informacin del episodio si termina\n","        if terminated or truncated:\n","            print(f\"Episode {self.episode_count}: Num Steps: {self.current_step}\")\n","            self.episode_count += 1\n","\n","        return observation, reward, terminated, truncated, info\n","\n","    def render(self, mode='human'):\n","        if mode == 'human':\n","            plt.figure(figsize=(6, 6))\n","            plt.scatter(self.agent_positions[:, 0], self.agent_positions[:, 1], color='blue', marker='o', label='Agent')\n","            plt.title('Agent Trajectory')\n","            plt.xlabel('X')\n","            plt.ylabel('Y')\n","            plt.axhline(0, color='black', linewidth=1, linestyle='--')\n","            plt.axvline(0, color='black', linewidth=1, linestyle='--')\n","            plt.grid(True, linestyle='--', alpha=0.5)\n","            plt.legend()\n","            plt.show()\n","        else:\n","            super(FreeMoveEnv, self).render(mode=mode)"],"metadata":{"id":"yyVssx4v9k-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","env = FreeMoveEnv()\n","\n","# Random agent\n","for episode in range(20):  # Run for 20 episodes\n","    total_reward = 0\n","    observations = []  # Almacena las observaciones para visualizacin\n","    observation = env.reset()\n","    for _ in range(env.max_steps):\n","        action = np.random.uniform(low=-1, high=1, size=(2,))\n","        observation, reward, done, _, _ = env.step(action)\n","        total_reward += reward\n","        observations.append(observation.copy())  # Almacena copia de la observacin\n","        if done:\n","            print(f\"Episode {episode + 1} finished. Total Reward Accumulated: {total_reward}\")\n","\n","            # Visualize the trajectory after each episode is finished\n","            env.render()\n","            plt.plot(np.array(observations)[:, 0], np.array(observations)[:, 1], label='Trajectory', color='orange')\n","            plt.legend()\n","            plt.show()\n","\n","            break\n","\n","env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2qLR3wUWhCc1","executionInfo":{"status":"ok","timestamp":1706108758926,"user_tz":-60,"elapsed":14053,"user":{"displayName":"Iker Etxebeste Arroyo","userId":"06101170301682302069"}},"outputId":"6e646623-4475-4b2a-b69f-92721f422bc2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["XUhDtCFJvPDZ","QHB9ZgR9wGhR","I-4R-iOpS8S8","fLmsf6fBUeSI","202m8zypTWQr","_EhYmwrhVb2h","Snkrvn40fyDr","LxPNf5yefJPR","Uy4nTDpkJV_L","UZl26BYhPXV4","prM6kFcr-Jcz","8PIO9xoi-Jc0","eioY98a_-Jc1","XaHRL4aCgJ3M","pLIUhhkQ-Jc6"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}